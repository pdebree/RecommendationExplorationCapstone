{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264fe412",
   "metadata": {},
   "source": [
    "# Exploring Recommendation System Suitability By User History Depth  \n",
    "## Data Imports and Cleaning\n",
    "Pippi de Bree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5bbb2",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "### [Introduction](#Introduction)\n",
    "\n",
    "### [Library Imports](#Imports)\n",
    "### [Lakh MIDI Dataset - Import and Cleaning](#Lakh-MIDI-Dataset)\n",
    "    - Dataset Description\n",
    "    - Dataset Cleaning\n",
    " \n",
    "    \n",
    "### [The Echo Nest Taste Profile Subset -  Import and Cleaning](#The-Echo-Nest-Taste-Profile-Subset) \n",
    "    - Dataset Desccription\n",
    "    - Dataset Cleaning \n",
    "    \n",
    " \n",
    "### [Intersection Data Creation](#Intersection)\n",
    "\n",
    "### [Audio File Intersection Creation](#Audio-Intersection)\n",
    "### [Conlusion of Data Loading and Cleaning](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16974f4",
   "metadata": {},
   "source": [
    "# Introduction <a id=Introduction a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b54b37",
   "metadata": {},
   "source": [
    "The dataset used in this exploration is the [The Lakh MIDI Dataset v0.1](https://colinraffel.com/projects/lmd/), a subset taken from the [Million Songs Dataset](http://millionsongdataset.com/). This subset includes the data from the Million Songs Dataset but matched with MIDI files for each track. (Audio files were obtained by reaching out to the owner). This dataset was combined with [The Echo Nest Taste Profile Subset](http://millionsongdataset.com/tasteprofile/), from the Million Songs Dataset in order to create a subset of Audio matched songs that have user taste information. This will allow us to create the recommendation system based on these user's tastes. \n",
    "\n",
    "References: \n",
    "*Thierry Bertin-Mahieux, Daniel P. W. Ellis, Brian Whitman, and Paul Lamere. \"The Million Song Dataset\". In Proceedings of the 12th International Society for Music Information Retrieval Conference, pages 591–596, 2011.*\n",
    "\n",
    "*Colin Raffel. \"Learning-Based Methods for Comparing Sequences, with Applications to Audio-to-MIDI Alignment and Matching\". PhD Thesis, 2016.*\n",
    "\n",
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bafa2f",
   "metadata": {},
   "source": [
    "# Library Imports <a id=Imports a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a6b3e",
   "metadata": {},
   "source": [
    "In order to work with our data we will import some libraries that will allow for easier data manipulation, namely `numpy` and `pandas`. These libraries let us easily transform our data to dataframes with a high level of functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a0a09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing numpy and pandas in order to gain functionality for working with .csv files\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df788c9",
   "metadata": {},
   "source": [
    "We will also import a custom library named `ds_utils_capstone` which contains a subset of utils functions that will be used accross this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cd2957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ds_utils_capstone from the current working directory. \n",
    "import ds_utils_capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e1239",
   "metadata": {},
   "source": [
    "# Lakh MIDI Dataset Import  <a id=Lakh-MIDI-Dataset a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b3063",
   "metadata": {},
   "source": [
    "## Data Set Description\n",
    "\n",
    "The Lakh MIDI dataset is a subset of the MSD dataset, with matching to a group of audio files (made available by the dataset creator). The following descriptions of the dataset are a outlines based on the [MSD website descriptions](#http://millionsongdataset.com/pages/example-track-description/), with some more research. This is an extensive list of attributes that will likely be edited.\n",
    "\n",
    "LMD-matched\n",
    "\n",
    "- `analysis_sample_rate`\tnot sure \n",
    "- `artist_7digitalid`\tIDs for artists in 7digital database\n",
    "- `artist_familiarity`\tMeasure of how known the artist is generally (e.g. Cyndi Lauper has 0.71)\n",
    "- `artist_hotttnesss`\tMeasure of how 'hot' or currently popular an artist is (Cyndi Lauper has 0.56) - could be time biased\n",
    "- `artist_id`\tID for artist in MSD \n",
    "- `artist_latitude`\tLatitude for artists location\n",
    "- `artist_location`\tArtist's declared location (e.g. Brooklyn, NY)\n",
    "- `artist_longitude`\tLongitude for artist's location\n",
    "- `artist_mbid`\tArtist ID for musicbrains.org\n",
    "- `artist_mbtags`\tTags this artist is associated with on musicbrainz.org  in list form (i.e. 'classis pop and rock')\n",
    "- `artist_mbtags_count`\tNumber of tags this artist has on musicbrainz.org\n",
    "- `artist_name`\tName of the Artist \n",
    "- `artist_playmeid`\tArtist ID for playme.com\n",
    "- `artist_terms`\tTags this artists is associated with on The Echo Nest (a main source for data) - a list\n",
    "- `artist_terms_freq`\tFrequency of usage of terms, as a proportion (0-1), when the artist is mentioned - as list e.g. \\[1, 0.6...]\n",
    "- `artist_terms_weight`\tWeight of the terms, list of proportions between 0 and 1 \n",
    "- `audio_md5`\tHash code for the audio used for analysis by The Echo Nest\n",
    "- `bars_confidence`\tConfidence value associated with start of each bar, from The Echo Nest\n",
    "- `bars_start`\tStart time of each bar, according to The Echo Nest \n",
    "- `beats_confidence`\tConfidence value associated with start of each beat, from The Echo Nest\n",
    "- `beats_start`\tStart time of each beat, accoring to The Echo Nest\n",
    "- `danceability`\tMeasure of how 'danceable' the song is (i.e. how easy it is to dance to - indicator of listening style) between 0 and 1.\n",
    "- `duration`\tLength of track, in seconds.\n",
    "- `end_of_fade_in`\tTime of the end of the fade in, at the beginning of the song, according to The Echo Nest\n",
    "- `energy`\tMeasure of how much 'energy' a song has, according to The Echo Nest. Between 0 and 1 (0 means not analysed).\n",
    "- `key`\tEstimation of the key, by The Echo Nest\n",
    "- `key_confidence` \tConfidence in the key estimation \n",
    "- `loudness`\tMeasure of the 'loudness' of a song (how much noise is present within a song)\n",
    "- `mode` \tEstimation of the mode, by The Echo Nest\n",
    "- `mode_confidence`\tConfidence in the mode estimation\n",
    "- `release`\tDate of release \n",
    "- `release_7digitalid`\tID of the album on the 7digital service \n",
    "- `sections_confidence`\tConfidence associated with each section according to The Echo Nest (between 0 and 1)\n",
    "- `sections_start`\tStart time of each section, according to The Echo Nest\n",
    "- `segments_confidence`\tConfidence value associated with each segment, by The Echo Nest\n",
    "- `segments_loudness_max`\tMax loudness during each segment (list)\n",
    "- `segments_loudness_max_time`\tTime of max loudness during each segment (list)\n",
    "- `segments_loudness_start`\tLoudness at the beginning of each segment\n",
    "- `segments_pitches`\tChroma features for each segment - normalised so max = 1\n",
    "- `segments_start`\tStart time of each segment \n",
    "- `segments_timbre`\tMFCC-like features for each segment\n",
    "- `silimar_artists`\tList of 100 artists (their Echo Nest ID) similar to this song's artist \n",
    "- `song_hotttnesss`\tAccording to The Echo Nest, when downloaded in 2010, the popularity/prevalence of the song (potentially outdated and time biased)\n",
    "- `song_id` \tID of song within MSD \n",
    "- `start_of_fade_out`\tStart time of fade out, in seconds, at the end of song \n",
    "- `tatums_confidence`\tConfidence in each tatum value (list)\n",
    "- `tatums_start`\tStart of each tatum (smallest interval between successive notes) according to Echo Nest\n",
    "- `tempo`\tTempo in BPM according to Echo Nest\n",
    "- `time_signature`\tTime signature according to The Echo Nest\n",
    "- `time_signature_confidence`\tConfidence in the time signature estimation \n",
    "- `title`\tTitle of the song (e.g. Never Gonna Give You Up)\n",
    "- `track_7digital` \tID of the song on 7digital \n",
    "- `track_id` \tID of track in The Echo Nest(used as a tag for .h5 files but song_id would be used to merge datasets).\n",
    "- `year`\tYear of song release, according to musicbrainz.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523795c6",
   "metadata": {},
   "source": [
    "## Accessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5f225",
   "metadata": {},
   "source": [
    "The data takes the form of hierarchical `.h5` files - meaning we need to expand these to create a `.csv` file. To do this we used code from the following:\n",
    "https://github.com/rcrdclub/mm-songs-db-tools\n",
    "\n",
    "However, some changes were made to allow this to work with the dataset. In hindsight, this preocessing may have been done using a different version of python, but only a few lines of code were changed. In order to execute this I ran the code below. This calls mmsongsdb_to_csv.py which creates a `.csv` by iterating all of the h5 files in the `lmd_matched_h5` dataset. I decided to use this subset because it gives me the option to add in MIDI or audio files. \n",
    "\n",
    "The code in the `mmsongsdb_to_csv.py` is from the github repo mentioned above - it iterates over the entire folder of nested `.h5` files. When it accesses each file, it calls `mmsongsdbtocsvconverter.py` which in adds each attribute in the HDF file to a growing `.csv` file by using the the `hdf5_getters.py`. \n",
    "\n",
    "The only change I made to this code is in the `mmsongsdbtocsvconverter.py` - this code is designed to be used with an older version of Python so I had some syntax issues but resolved them. \n",
    "\n",
    "The below code accesses the terminal to run the `mmsongsdb_to_csv.py` on the folder `lmd_matched_h5`, and thereby create `lmd.csv`. I have the code written below to show how I created the `lmd.csv` dataset, though do not recommend running it (this would take hours to execute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c07aea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to convert h5 files to a csv \n",
    "# ! python code_for_h5/mmsongsdb_to_csv.py data/lmd.csv data/lmd_matched_h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa19255",
   "metadata": {},
   "source": [
    "Having created the`lmd.csv`, we read it in as a pandas dataframe in order to look at the format of the data.\n",
    "\n",
    "To do so we will utilise the functionality of pandas and numpy and use the function created in the `ds_utils_capstone.py` file that can be found in the current directory. Throughout this project we will use functions created within this file, as give us more functionality accross workbooks.  \n",
    "\n",
    "Below we list the imports needed for this data cleaning stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18cace",
   "metadata": {},
   "source": [
    "Now we will read in the data as a `.csv` file using the `ds_utils_capstone` function `.read_csv_pd`. This code is written for direct use of the local data - it is very large so a copy has been saved in [this](https://drive.google.com/drive/folders/12nRIYn6zHiYHOLe4or-fGiN7FAAdxTnW) Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c6b91fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame contains 124136 rows and 54 columns.\n",
      "Missing values or duplicated rows found.\n"
     ]
    }
   ],
   "source": [
    "# Reading in the .csv file created from the h5 files, using ds_utils_capstone read-in function \n",
    "lmd = ds_utils_capstone.read_csv_pd(\"data/lmd.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014acc6",
   "metadata": {},
   "source": [
    "## Dataset Shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31ee25",
   "metadata": {},
   "source": [
    "From the above output we can see the created dataset has 124,136 rows and 54 columns. However, we know from the data source that the intersection is only supposed to be 45,129 songs. This means there was an error in the import. (This is an issue that could be returned to). The read-in of the data was successfulw with the first few rows looking as they should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e77f32aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_sample_rate</th>\n",
       "      <th>artist_7digitalid</th>\n",
       "      <th>artist_familiarity</th>\n",
       "      <th>artist_hotttnesss</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_mbid</th>\n",
       "      <th>artist_mbtags</th>\n",
       "      <th>...</th>\n",
       "      <th>start_of_fade_out</th>\n",
       "      <th>tatums_confidence</th>\n",
       "      <th>tatums_start</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>title</th>\n",
       "      <th>track_7digitalid</th>\n",
       "      <th>track_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22050</td>\n",
       "      <td>11319</td>\n",
       "      <td>0.712886</td>\n",
       "      <td>0.559257</td>\n",
       "      <td>ARGE7G11187FB37E05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7bd9e20e-74b9-446a-a2ed-a223f82a36e7</td>\n",
       "      <td>['classic pop and rock']</td>\n",
       "      <td>...</td>\n",
       "      <td>240.640</td>\n",
       "      <td>[1.    1.    1.    1.    1.    1.    1.    1. ...</td>\n",
       "      <td>[1.2807000e-01 3.7284000e-01 6.1882000e-01 8.6...</td>\n",
       "      <td>123.989</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "      <td>Into The Nightlife</td>\n",
       "      <td>3110092</td>\n",
       "      <td>TRAAAGR128F425B14B</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22050</td>\n",
       "      <td>93189</td>\n",
       "      <td>0.546102</td>\n",
       "      <td>0.383787</td>\n",
       "      <td>ARJJ8611187FB5321F</td>\n",
       "      <td>40.79086</td>\n",
       "      <td>New York, NY [Manhattan]</td>\n",
       "      <td>-73.96644</td>\n",
       "      <td>471e21ab-7a14-4190-a9d2-f95197616df4</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>167.607</td>\n",
       "      <td>[1.    1.    1.    1.    1.    1.    1.    1. ...</td>\n",
       "      <td>[  0.76749   1.04856   1.32007   1.59294   1.8...</td>\n",
       "      <td>110.129</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711</td>\n",
       "      <td>Break My Stride</td>\n",
       "      <td>8473798</td>\n",
       "      <td>TRAAAZF12903CCCF6B</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22050</td>\n",
       "      <td>1396</td>\n",
       "      <td>0.707200</td>\n",
       "      <td>0.513463</td>\n",
       "      <td>ARYKCQI1187FB3B18F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eeacb319-8d4c-48e0-80a0-944e71c375bf</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>285.605</td>\n",
       "      <td>[0.238 0.232 0.216 ... 0.    0.    0.   ]</td>\n",
       "      <td>[5.7280000e-02 2.6051000e-01 4.6674000e-01 ......</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4</td>\n",
       "      <td>0.931</td>\n",
       "      <td>Caught In A Dream</td>\n",
       "      <td>4143071</td>\n",
       "      <td>TRAABVM128F92CA9DC</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22050</td>\n",
       "      <td>611</td>\n",
       "      <td>0.635346</td>\n",
       "      <td>0.463478</td>\n",
       "      <td>ARD9UVF1187B9B17FE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawthorne, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>634fe78e-fc6b-4b2a-ba83-c8c66e13a8aa</td>\n",
       "      <td>['classic pop and rock']</td>\n",
       "      <td>...</td>\n",
       "      <td>160.717</td>\n",
       "      <td>[0.897 0.839 0.784 0.759 0.68  0.641 0.604 0.5...</td>\n",
       "      <td>[  0.23383   0.54057   0.84423   1.15034   1.4...</td>\n",
       "      <td>100.494</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Keep An Eye On Summer (Album Version)</td>\n",
       "      <td>1140917</td>\n",
       "      <td>TRAABXH128F42955D6</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22050</td>\n",
       "      <td>153505</td>\n",
       "      <td>0.583006</td>\n",
       "      <td>0.333922</td>\n",
       "      <td>ARDDIBO1187B9B0822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7720a649-0c70-4c7a-972a-c29ccb898201</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>156.973</td>\n",
       "      <td>[0.894 0.808 0.741 0.676 0.631 0.598 0.571 0.5...</td>\n",
       "      <td>[  0.27878   0.53605   0.7946    1.05329   1.3...</td>\n",
       "      <td>118.430</td>\n",
       "      <td>4</td>\n",
       "      <td>0.610</td>\n",
       "      <td>Summer</td>\n",
       "      <td>7473946</td>\n",
       "      <td>TRAACQE12903CC706C</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_sample_rate  artist_7digitalid  artist_familiarity  \\\n",
       "0                 22050              11319            0.712886   \n",
       "1                 22050              93189            0.546102   \n",
       "2                 22050               1396            0.707200   \n",
       "3                 22050                611            0.635346   \n",
       "4                 22050             153505            0.583006   \n",
       "\n",
       "   artist_hotttnesss           artist_id  artist_latitude  \\\n",
       "0           0.559257  ARGE7G11187FB37E05              NaN   \n",
       "1           0.383787  ARJJ8611187FB5321F         40.79086   \n",
       "2           0.513463  ARYKCQI1187FB3B18F              NaN   \n",
       "3           0.463478  ARD9UVF1187B9B17FE              NaN   \n",
       "4           0.333922  ARDDIBO1187B9B0822              NaN   \n",
       "\n",
       "            artist_location  artist_longitude  \\\n",
       "0              Brooklyn, NY               NaN   \n",
       "1  New York, NY [Manhattan]         -73.96644   \n",
       "2                       NaN               NaN   \n",
       "3             Hawthorne, CA               NaN   \n",
       "4                       NaN               NaN   \n",
       "\n",
       "                            artist_mbid             artist_mbtags  ...  \\\n",
       "0  7bd9e20e-74b9-446a-a2ed-a223f82a36e7  ['classic pop and rock']  ...   \n",
       "1  471e21ab-7a14-4190-a9d2-f95197616df4                        []  ...   \n",
       "2  eeacb319-8d4c-48e0-80a0-944e71c375bf                        []  ...   \n",
       "3  634fe78e-fc6b-4b2a-ba83-c8c66e13a8aa  ['classic pop and rock']  ...   \n",
       "4  7720a649-0c70-4c7a-972a-c29ccb898201                        []  ...   \n",
       "\n",
       "  start_of_fade_out                                  tatums_confidence  \\\n",
       "0           240.640  [1.    1.    1.    1.    1.    1.    1.    1. ...   \n",
       "1           167.607  [1.    1.    1.    1.    1.    1.    1.    1. ...   \n",
       "2           285.605          [0.238 0.232 0.216 ... 0.    0.    0.   ]   \n",
       "3           160.717  [0.897 0.839 0.784 0.759 0.68  0.641 0.604 0.5...   \n",
       "4           156.973  [0.894 0.808 0.741 0.676 0.631 0.598 0.571 0.5...   \n",
       "\n",
       "                                        tatums_start    tempo time_signature  \\\n",
       "0  [1.2807000e-01 3.7284000e-01 6.1882000e-01 8.6...  123.989              4   \n",
       "1  [  0.76749   1.04856   1.32007   1.59294   1.8...  110.129              4   \n",
       "2  [5.7280000e-02 2.6051000e-01 4.6674000e-01 ......  150.062              4   \n",
       "3  [  0.23383   0.54057   0.84423   1.15034   1.4...  100.494              3   \n",
       "4  [  0.27878   0.53605   0.7946    1.05329   1.3...  118.430              4   \n",
       "\n",
       "  time_signature_confidence                                  title  \\\n",
       "0                     0.800                     Into The Nightlife   \n",
       "1                     0.711                        Break My Stride   \n",
       "2                     0.931                      Caught In A Dream   \n",
       "3                     1.000  Keep An Eye On Summer (Album Version)   \n",
       "4                     0.610                                 Summer   \n",
       "\n",
       "  track_7digitalid            track_id  year  \n",
       "0          3110092  TRAAAGR128F425B14B  2008  \n",
       "1          8473798  TRAAAZF12903CCCF6B  1983  \n",
       "2          4143071  TRAABVM128F92CA9DC  2004  \n",
       "3          1140917  TRAABXH128F42955D6  1998  \n",
       "4          7473946  TRAACQE12903CC706C  2007  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the first few rows of the data \n",
    "lmd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997724b",
   "metadata": {},
   "source": [
    "The format of the data seems to make sense, so we will look at the columns and see if we find any issues in how the columns were imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "796515bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['analysis_sample_rate', 'artist_7digitalid', 'artist_familiarity',\n",
       "       'artist_hotttnesss', 'artist_id', 'artist_latitude', 'artist_location',\n",
       "       'artist_longitude', 'artist_mbid', 'artist_mbtags',\n",
       "       'artist_mbtags_count', 'artist_name', 'artist_playmeid', 'artist_terms',\n",
       "       'artist_terms_freq', 'artist_terms_weight', 'audio_md5',\n",
       "       'bars_confidence', 'bars_start', 'beats_confidence', 'beats_start',\n",
       "       'danceability', 'duration', 'end_of_fade_in', 'energy', 'key',\n",
       "       'key_confidence', 'loudness', 'mode', 'mode_confidence', 'release',\n",
       "       'release_7digitalid', 'sections_confidence', 'sections_start',\n",
       "       'segments_confidence', 'segments_loudness_max',\n",
       "       'segments_loudness_max_time', 'segments_loudness_start',\n",
       "       'segments_pitches', 'segments_start', 'segments_timbre',\n",
       "       'similar_artists', 'song_hotttnesss', 'song_id', 'start_of_fade_out',\n",
       "       'tatums_confidence', 'tatums_start', 'tempo', 'time_signature',\n",
       "       'time_signature_confidence', 'title', 'track_7digitalid', 'track_id',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660bdcd",
   "metadata": {},
   "source": [
    "From this we can see that we have a lot of attributes, but none that are extra as they all match the data description.\n",
    "We will look further into these columns in our Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8675f7",
   "metadata": {},
   "source": [
    "## Duplicated Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f010dd1",
   "metadata": {},
   "source": [
    "We may now consider that we have an issue of duplicated rows. First we will count the number of duplicated rows to see if this is the cause of our issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3ef97a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicated rows are: 93102\n"
     ]
    }
   ],
   "source": [
    "# We will look at the number of duplicated rows.\n",
    "print(\"The number of duplicated rows are:\", lmd.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716026a",
   "metadata": {},
   "source": [
    "To see the number of non-duplicated rows we will use the boolean output of the `.duplicated()` to select only rows that are designated as `False`. By default, the function marks the first instance of every duplicated row as `False` in order to let us keep one instance of the duplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d89c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-duplicated rows are: 31034\n"
     ]
    }
   ],
   "source": [
    "# The number of non\n",
    "print(\"The number of non-duplicated rows are:\", len(lmd[lmd.duplicated() == False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8d68b",
   "metadata": {},
   "source": [
    "As we have 124,136 rows total, we should hope that the number of duplicated and non-duplicated rows add up:\n",
    "\n",
    "31034 + 93102 = 124136 \n",
    "\n",
    "Therefore we have exactly 3 times as many duplicates as rows, this may be the result of an issue in our import. \n",
    "\n",
    "We have successfully isolated singular instances of each row, so we will create a dataframe with only the singular instances. This will allow us to continue on with our exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e5b2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with only one instance of every row. \n",
    "lmd_no_dup = lmd[lmd.duplicated() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182c496",
   "metadata": {},
   "source": [
    "As a check, we will see if this gives us the expected number of rows (matching the above output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73531508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of singular instance dataframe: 31034\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of singular instance dataframe:\", len(lmd_no_dup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcd04b",
   "metadata": {},
   "source": [
    "This gives us the correct number of rows - 31034. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2a0e9",
   "metadata": {},
   "source": [
    "## Missing Data \n",
    "\n",
    "Now we are going to look into missing data in order to see if there are any serious issues. We will use the `.info()` function to see if any of the columns are missing data points. It also allows us to look at data types, but we will address those later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20f93a3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31034 entries, 0 to 91877\n",
      "Data columns (total 54 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   analysis_sample_rate        31034 non-null  int64  \n",
      " 1   artist_7digitalid           31034 non-null  int64  \n",
      " 2   artist_familiarity          31030 non-null  float64\n",
      " 3   artist_hotttnesss           31034 non-null  float64\n",
      " 4   artist_id                   31034 non-null  object \n",
      " 5   artist_latitude             10507 non-null  float64\n",
      " 6   artist_location             17438 non-null  object \n",
      " 7   artist_longitude            10507 non-null  float64\n",
      " 8   artist_mbid                 29049 non-null  object \n",
      " 9   artist_mbtags               31034 non-null  object \n",
      " 10  artist_mbtags_count         31034 non-null  object \n",
      " 11  artist_name                 31034 non-null  object \n",
      " 12  artist_playmeid             31034 non-null  int64  \n",
      " 13  artist_terms                31034 non-null  object \n",
      " 14  artist_terms_freq           31034 non-null  object \n",
      " 15  artist_terms_weight         31034 non-null  object \n",
      " 16  audio_md5                   31034 non-null  object \n",
      " 17  bars_confidence             31034 non-null  object \n",
      " 18  bars_start                  31034 non-null  object \n",
      " 19  beats_confidence            31034 non-null  object \n",
      " 20  beats_start                 31034 non-null  object \n",
      " 21  danceability                31034 non-null  float64\n",
      " 22  duration                    31034 non-null  float64\n",
      " 23  end_of_fade_in              31034 non-null  float64\n",
      " 24  energy                      31034 non-null  float64\n",
      " 25  key                         31034 non-null  int64  \n",
      " 26  key_confidence              31034 non-null  float64\n",
      " 27  loudness                    31034 non-null  float64\n",
      " 28  mode                        31034 non-null  int64  \n",
      " 29  mode_confidence             31034 non-null  float64\n",
      " 30  release                     31034 non-null  object \n",
      " 31  release_7digitalid          31034 non-null  int64  \n",
      " 32  sections_confidence         31034 non-null  object \n",
      " 33  sections_start              31034 non-null  object \n",
      " 34  segments_confidence         31034 non-null  object \n",
      " 35  segments_loudness_max       31034 non-null  object \n",
      " 36  segments_loudness_max_time  31034 non-null  object \n",
      " 37  segments_loudness_start     31034 non-null  object \n",
      " 38  segments_pitches            31034 non-null  object \n",
      " 39  segments_start              31034 non-null  object \n",
      " 40  segments_timbre             31034 non-null  object \n",
      " 41  similar_artists             31034 non-null  object \n",
      " 42  song_hotttnesss             15992 non-null  float64\n",
      " 43  song_id                     31034 non-null  object \n",
      " 44  start_of_fade_out           31034 non-null  float64\n",
      " 45  tatums_confidence           31034 non-null  object \n",
      " 46  tatums_start                31034 non-null  object \n",
      " 47  tempo                       31034 non-null  float64\n",
      " 48  time_signature              31034 non-null  int64  \n",
      " 49  time_signature_confidence   31034 non-null  float64\n",
      " 50  title                       31034 non-null  object \n",
      " 51  track_7digitalid            31034 non-null  int64  \n",
      " 52  track_id                    31034 non-null  object \n",
      " 53  year                        31034 non-null  int64  \n",
      "dtypes: float64(15), int64(9), object(30)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "lmd_no_dup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7adf02a",
   "metadata": {},
   "source": [
    "From this we can see that the columns we may have problems with are `artist_latitude`, `artist_location`, `artist_longitude`, `artist_mbid` and `song_hotttnesss`. \n",
    "\n",
    "If you think about music as localised it may make sense that people would listen to music from their areas - in specific more underground and local music scenes would have specific local users - it could be interesting to look into this, especially if we had user location data. However, we do not, so we can move on from using this location data. Overall, it seems unlikely that location would have a large impact. Though there are more data points missing from the `artist_latitude` and `artist_longitude` than from the `artist_location` - we still cannot use the `artist_location` because too many values are missing. \n",
    "\n",
    "Missing `artist_mbid` is not a big issue because this is data that we would not use. This attribute is the artist id for musicbrains.org - as we are not using data from this website we are not concerned that we are missing this data (we will simply not use the column).\n",
    "\n",
    "Finally, the `song_hotttnesss` attribute is missing about half of it's data. The data source said that this was a measure of the prevalence of the song in 2010 (when the dataset was created), and this may be helpful to the dataset. However, it is not logical to create values for this data, as about half of it is missing.\n",
    "\n",
    "Therefore, we will continue on without these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32f1d2f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dropping the attributes with too many missing values\n",
    "lmd_no_dup = lmd_no_dup.drop(columns=['artist_latitude', 'artist_location', 'artist_longitude', 'artist_mbid',\n",
    "                      'song_hotttnesss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "827dca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of columns.\n",
    "len(lmd_no_dup.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782bb0d",
   "metadata": {},
   "source": [
    "After dropping the missing values columns we have 49 columns. \n",
    "\n",
    "Now we can look more deeply into our attributes. From the description list above we can see that there are many columns that will not be helpful to us as they reference different datasets or website that will not be used in this analysis. We will go through each column, and decide whether we want to bring them into our EDA. We will also consider datatypes as we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db432b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31034 entries, 0 to 91877\n",
      "Data columns (total 49 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   analysis_sample_rate        31034 non-null  int64  \n",
      " 1   artist_7digitalid           31034 non-null  int64  \n",
      " 2   artist_familiarity          31030 non-null  float64\n",
      " 3   artist_hotttnesss           31034 non-null  float64\n",
      " 4   artist_id                   31034 non-null  object \n",
      " 5   artist_mbtags               31034 non-null  object \n",
      " 6   artist_mbtags_count         31034 non-null  object \n",
      " 7   artist_name                 31034 non-null  object \n",
      " 8   artist_playmeid             31034 non-null  int64  \n",
      " 9   artist_terms                31034 non-null  object \n",
      " 10  artist_terms_freq           31034 non-null  object \n",
      " 11  artist_terms_weight         31034 non-null  object \n",
      " 12  audio_md5                   31034 non-null  object \n",
      " 13  bars_confidence             31034 non-null  object \n",
      " 14  bars_start                  31034 non-null  object \n",
      " 15  beats_confidence            31034 non-null  object \n",
      " 16  beats_start                 31034 non-null  object \n",
      " 17  danceability                31034 non-null  float64\n",
      " 18  duration                    31034 non-null  float64\n",
      " 19  end_of_fade_in              31034 non-null  float64\n",
      " 20  energy                      31034 non-null  float64\n",
      " 21  key                         31034 non-null  int64  \n",
      " 22  key_confidence              31034 non-null  float64\n",
      " 23  loudness                    31034 non-null  float64\n",
      " 24  mode                        31034 non-null  int64  \n",
      " 25  mode_confidence             31034 non-null  float64\n",
      " 26  release                     31034 non-null  object \n",
      " 27  release_7digitalid          31034 non-null  int64  \n",
      " 28  sections_confidence         31034 non-null  object \n",
      " 29  sections_start              31034 non-null  object \n",
      " 30  segments_confidence         31034 non-null  object \n",
      " 31  segments_loudness_max       31034 non-null  object \n",
      " 32  segments_loudness_max_time  31034 non-null  object \n",
      " 33  segments_loudness_start     31034 non-null  object \n",
      " 34  segments_pitches            31034 non-null  object \n",
      " 35  segments_start              31034 non-null  object \n",
      " 36  segments_timbre             31034 non-null  object \n",
      " 37  similar_artists             31034 non-null  object \n",
      " 38  song_id                     31034 non-null  object \n",
      " 39  start_of_fade_out           31034 non-null  float64\n",
      " 40  tatums_confidence           31034 non-null  object \n",
      " 41  tatums_start                31034 non-null  object \n",
      " 42  tempo                       31034 non-null  float64\n",
      " 43  time_signature              31034 non-null  int64  \n",
      " 44  time_signature_confidence   31034 non-null  float64\n",
      " 45  title                       31034 non-null  object \n",
      " 46  track_7digitalid            31034 non-null  int64  \n",
      " 47  track_id                    31034 non-null  object \n",
      " 48  year                        31034 non-null  int64  \n",
      "dtypes: float64(12), int64(9), object(28)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "lmd_no_dup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53bbb0a",
   "metadata": {},
   "source": [
    "Firstly, looking `analysis_sample_rate` we found no description of what it is and therefore cannot infer anything from it's values. \n",
    "\n",
    "The attributes that reference different datasets or attributes in different datasets are:\n",
    "- `artist_7digitalid` - artist reference id for the 7digital platform\n",
    "- `artist_playmeid` - artist reference id for playme.com\n",
    "- `release_7digitalid` - album reference for the 7digital platform\n",
    "- `track_7digitalid` - track reference for the 7digital platform\n",
    "- `artist_mbtags` - tags associated with the artist on musicbrainz.org (we will remove this because terms from the original dataset will serve a similar function).\n",
    "- `artist_mbtags_count` - number of times the musicbrainz.org tags are used in reference to the artist\n",
    "- `audio_m5` - a code used to link audio to the main dataset, we will not need this. \n",
    "\n",
    "We will drop all of these variables, as they will not aide our analysis. As we have dropped them their data types do not matter. Now we will look at which variables we believe are not well suited to out analysis, even though they are musical in nature. \n",
    "- `bars_start` and `bars_confidence` - give the start time of every bar in the songs, and the confidence behind these calculations. This seems like it is too specific a timing interval and in itself would not bring any value to how users listen to songs. (It could be argued that number of bar starts hint at duration and tempo, but we have those attributes so do not need bars information. \n",
    "- `beats_start` and `beats_confidence` - give the start time of every beat in the song, with the confidence. Similarly to the bars, this information seems unhelpful because what would be used to infer user listening habits is already overed in other attributes. \n",
    "- `tatums_start` and `tatums_confidence` - give the start time of every tatum (a very small section of a note) and the confidence. Again, the information that could be infered from these attributes can be found elsewhere and the data is too specific for our analysis.\n",
    "- `segments_confidence`, `segments_loudness_max`, `segments_loudness_max_time`, `segments_loudness_start`, `segments_pitches`, `segments_start`, `segments_timbre` - A segment, according to the MSD is a musical event, or onset. The sample song for the dataset has 935 segments. This is a lot of specific and localised data for our recommendation system, so we will remove this segment data and instead focus on using the section data (sample song only has 10). This will aide in computational load and the lost specificity will likely not be missed.\n",
    "\n",
    "To drop: \n",
    "- `analysis_sample_rate`\n",
    "- `artist_7digitalid`\n",
    "- `artist_playmeid`\n",
    "- `release_7digitalid`\n",
    "- `track_7digitalid`\n",
    "- `artist_mbtags`\n",
    "- `artist_mbtags_count`\n",
    "- `audio_m5` \n",
    "- `bars_start`\n",
    "- `bars_confidence`\n",
    "- `beats_start`\n",
    "- `beats_confidence`\n",
    "- `tatums_start`\n",
    "- `tatums_confidence`\n",
    "- `segments_confidence`\n",
    "- `segments_loudness_max` \n",
    "- `segments_loudness_max_time` \n",
    "- `segments_loudness_start` \n",
    "- `segments_pitches` \n",
    "- `segments_start` \n",
    "- `segments_timbre`\n",
    "\n",
    "We use the pandas `.drop()` method to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce0e7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "lmd_clean = lmd_no_dup.drop(columns=[\n",
    "    'analysis_sample_rate',\n",
    "    'artist_7digitalid',\n",
    "    'artist_playmeid',\n",
    "    'release_7digitalid',\n",
    "    'track_7digitalid',\n",
    "    'artist_mbtags',\n",
    "    'artist_mbtags_count',\n",
    "    'audio_md5', \n",
    "    'bars_start',\n",
    "    'bars_confidence',\n",
    "    'beats_start',\n",
    "    'beats_confidence',\n",
    "    'tatums_start',\n",
    "    'tatums_confidence',\n",
    "    'segments_confidence',\n",
    "    'segments_loudness_max', \n",
    "    'segments_loudness_max_time',\n",
    "    'segments_loudness_start', \n",
    "    'segments_pitches', \n",
    "    'segments_start',\n",
    "    'segments_timbre'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381d440",
   "metadata": {},
   "source": [
    "As we are dropping 21 columns, we expect to end up with 28 left over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da5fc91b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns left after cleaning: 28\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns left after cleaning:\", len(lmd_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a695bc",
   "metadata": {},
   "source": [
    "Now we can consider the data types of the attributes that we have remaining:\n",
    "\n",
    "- `artist_familiarity` - As a measure (from 0 to 1) it makes sense that this is a float.\n",
    "- `artist_hotttnesss` - As a measure (from 0 to 1) it makes sense that this is a float.\n",
    "- `artist_id` - As a alphanumerical value, it makes sense that this is an object.\n",
    "- `artist_name` - As a string, it makes sense that this is an object.\n",
    "- `artist_terms` - As a list of strings, it makes sense that this is an object. \n",
    "- `artist_terms_freq` - As a list of floats, it makes sense that this is an object.\n",
    "- `artist_terms_weight` - As a list of floats, it makes sense that this is an object.\n",
    "- `duration` - As a value for the length of a song, it makes sense that this is a float.\n",
    "- `danceability` - As a measure (from 0 to 1) it makes sense that this is a float.\n",
    "- `end_of_fade_in` - As a value for the time at which the fade in ends, it makes sense that this is a float.\n",
    "- `energy` - As a measure (from 0 to 1) it makes sense that this is a float.\n",
    "- `key` - The key is numeric in this case, for easier categorisation, so it makes sense that this is an int. \n",
    "- `key_confidence` - As a measure (from 0 to 1) it makes sense that this is a float.\n",
    "- `loudness` - The value of the loudness is measured in a way such that it makes sense for it to be a float.\n",
    "- `mode` - Similar to key, the mode of the song is numeric here for easier cateogorisation, so it makes sense that it is an int.\n",
    "- `mode_confidence` - As a measure (from 0 to 1) it makes sense that this is a float.\n",
    "- `release` - As a string, it makes sense that this is an object.\n",
    "- `sections_confidence` - As a list of ints, it makes sense that this is an object (we will need to consider expanding)\n",
    "- `sections_start` - As a list of ints, it makes sense that this is an object (we will need to consider expanding)\n",
    "- `similar_artists` - As a list of strings, it makes sense that this is an object (we will need to consider expanding)\n",
    "- `song_id` - As a alphanumerical value, it makes sense that this is an object. \n",
    "- `start_of_fade_out` - As a value for the time at which the fade our starts, it makes sense that this is a float.\n",
    "- `tempo` - As a measure of beats per minute, it makes sense that this is a float. \n",
    "- `time_signature` - It makes sense for this to be an int because this value will be an integer\n",
    "- `time_signature_confidence` - As a measure (from 0 to 1) of the confidence of the time signature, it makes sense that this is a float.\n",
    "- `title` - As a string, it makes sense that this is an object.\n",
    "- `track_id` - As a alphanumerical value, it makes sense that this is an object. \n",
    "- `year` - The year attribute is an int which makes sense given that it is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5685d802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31034, 28)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmd_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9186e4d",
   "metadata": {},
   "source": [
    "# The Echo Nest Taste Profile Subset Import and Cleaning <a id=The-Echo-Nest-Taste-Profile-Subset a>\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The user data for our recommendation system comes from [The Echo Nest Taste Profile](http://millionsongdataset.com/tasteprofile/). It takes the form of a tab separated value with three columns; `user`, `song` and `count`.\n",
    "\n",
    "- `user` - contains an identification number for the user who listened to the song. \n",
    "- `song` - contains the song identification number, which can be paired with `song_id` in the Lakh Dataset\n",
    "- `count` - countains the number of times the user listened to the song.\n",
    "\n",
    "For the entire dataset, each user appears at least 10 times, meaning there are 10 songs associated with each user. Overall, the dataset contains 1,019,318 unique users, 384,546 unique MSD songs and 48,373,586 user play-count data points. \n",
    "\n",
    "The dataset comes in the form of a `.txt` file but the three columns are separated by tabs. We will look into the beginning of the file using the below command line code (again, this is commented out because it has a very long run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ad6af46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will show the beginning of the .txt file to see if we correctly import it \n",
    "# ! head data/train_triplets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33e02a",
   "metadata": {},
   "source": [
    "We know now that there is no introduction or column titles, so using the `.read_csv` method with a tab separation correctly should give us the correct beginning. This code is written for direct use of the local data - it is very large so a copy has been saved in [this](https://drive.google.com/drive/folders/12nRIYn6zHiYHOLe4or-fGiN7FAAdxTnW) Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50958fde",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train_triplets.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The dataset is tab separated, and has no column titles, so we name them below. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plays \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/train_triplets.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msong\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capenv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capenv/lib/python3.8/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train_triplets.txt'"
     ]
    }
   ],
   "source": [
    "# The dataset is tab separated, and has no column titles, so we name them below. \n",
    "plays = pd.read_csv(\"data/train_triplets.txt\", sep=\"\\t\", header=None, names=['user', 'song', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a82b63",
   "metadata": {},
   "source": [
    "From this read in we know that there are no missing values or duplicated values. We will alo check that we have correctly read in our data by comparing the head of our command line code to the head of our pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccbd9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The head method shows the first 5 values of the dataframe.\n",
    "plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390c5c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The shape attribute shows us the number of data points we have in the dataset. \n",
    "plays.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ceb27",
   "metadata": {},
   "source": [
    "## Datatypes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be104f63",
   "metadata": {},
   "source": [
    "We will check the data types of the columns in the Taste Profile by using the `.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53b446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking at the information for the columns\n",
    "plays.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624354d7",
   "metadata": {},
   "source": [
    "We can see from this output that `user` and `song` are object types, which makes sense given that these identifier are both alphanumeric values. Then we can see that `count` is an int, this is appropriate because the value should be a finite whole number for each row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc64cb7",
   "metadata": {},
   "source": [
    "At this point we could save our data as a `.csv` file in order to keep the full dataset in a format that could be  more easily used. However, the dataset is very large so we will not do this in the practical report of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa333b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the plays data to a csv file\n",
    "# plays.to_csv(\"data/play_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f538311",
   "metadata": {},
   "source": [
    "# Intersection Dataset Creation <a id=Intersection a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073021b6",
   "metadata": {},
   "source": [
    "The code above shows us there are are 48,373,586 unique data points that come from any songs in the entire Million Songs Dataset. However, we are only using a subset of the full dataset (tracks that are matched to audio files) so we will look into how this dataset interacts with the Lakh Dataset. To do so we will first look at the intersection of the two datasets, firstly at how many of the songs in the Taste Profile are present in the Lakh Dataset. \n",
    "\n",
    "We will create the intersection of songs that appear in the Taste Profile and the Lakh, doing this here will seriously reduce the size of our dataset and allow for much easier storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique songs in the Taste Profile\n",
    "unique_play_songs = plays['song'].unique()\n",
    "print(\"The number of unique songs in the Taste Profile is:\", len(unique_play_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique songs in the Lakh Dataset\n",
    "unique_lmd_songs = lmd_clean[\"song_id\"].unique()\n",
    "print(\"The number of unique songs in the Lakh Dataset is:\", len(unique_lmd_songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cdf3e9",
   "metadata": {},
   "source": [
    "The Lakh dataset has far fewer songs, so now we want to find how large the intersection between these two is. If it is large enough we will be able to use this as our dataset and have audio data as well as user data. To find this intersection we create sets for both song groups, giving us only the unique values. Then we will make a list of the songs that are in both by using the `&` conditional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the unique songs that are in both \n",
    "intersect_songs = list(set(unique_play_songs) & set(unique_lmd_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of songs in intersection of the Taste Profile and Lakh Dataset is:\\n\", len(intersect_songs) ,sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6156e",
   "metadata": {},
   "source": [
    "Though this is not a huge dataset, we will continue on with it because if it was much larger we would begin to get a serious issue of computational load (especially if we begin to consider audio data). We will now look at how big the Lakh Subset will be if we only include these songs and how much user data we get if we only include these songs. \n",
    "\n",
    "First we will look at the Lakh Dataset with only the intersection songs. To do so we will use the `song_id` attribute and compare it to the `intersect_songs` list. This should act as a sanity check, as if there are no duplicated songs in the dataset we should see 11890 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will check the number of data points with songs in the intersect_songs like\n",
    "lmd_clean['song_id'].isin(intersect_songs).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed20242",
   "metadata": {},
   "source": [
    "This matches our assumption, so we will now add these rows to a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb434c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "sect_lmd = lmd_clean[lmd_clean['song_id'].isin(intersect_songs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dataframe length \n",
    "len(sect_lmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167208b7",
   "metadata": {},
   "source": [
    "Now we know that we have 11890 songs, with matched audio data that appear in our taste profile song. At this point we will save our cleaned subset as `sect_lmd.csv`, so that we can continue our exploration of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd40298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the subset dataset\n",
    "sect_lmd.to_csv(\"data/sect_lmd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdb3dd",
   "metadata": {},
   "source": [
    "We will now look into how many times each of these songs appear in the Taste Profile, by creating a subset of the Taste Profile that includes every instances of the songs in the `intersect_songs` list. First we will see how large this set is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32586094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of unique user-song-count combinations that contain a song in the intersection. \n",
    "plays['song'].isin(intersect_songs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_plays = plays[plays['song'].isin(intersect_songs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b2664",
   "metadata": {},
   "source": [
    "This is a very encouraging result, as it suggests that, on average, we have over 500 occurances of each song in the user profile. This suggests that we have a lot of data to create a specific categorisation/view of every track. We will also export this subset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_plays.to_csv(\"data/sect_plays.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f376346",
   "metadata": {},
   "source": [
    "# Audio Intersection Matching <a id=Audio-Intersection a>\n",
    "\n",
    "We now we want to reduce our audio files to only include those with songs in the `intersection_songs`. As the audio files are saved under their track names, not song names, we want to check that there are matched one-to-one, and that there are no tracks or songs that appear multiple times. In order to do this we will compare the number of unique songs, unique tracks and unique song and track group by combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db853b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique songs in the sect_lmd\n",
    "print(\"The number of unique songs:\", sect_lmd['song_id'].nunique())\n",
    "print(\"The number of unique tracks:\", sect_lmd['track_id'].nunique())\n",
    "print(\"The number of unique song/track combinations:\",len(sect_lmd.groupby(['song_id', 'track_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8f666",
   "metadata": {},
   "source": [
    "Now we know that each song matches exactly one track. If we pick the tracks from the audio files that are in the `sect_lmd` data, we know that they are associated with a song in the `intersect_songs` set. Meaning we are only picking files that match our subset. We will likely do this iteration over the audio files from the command line, so we can create a file that contains only the names of the tracks for easier iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of the tracks in the subset\n",
    "sect_tracks = sect_lmd['track_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not actually need to create this subset, so we will not export the data\n",
    "#sect_tracks.to_csv('data/sect_tracks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a2850",
   "metadata": {},
   "source": [
    "The collection of the Audio files into a format that would be usable with the rest of our dataset will be done in a separate notebook **1B_audio_subset**. This is done because the data takes a very different format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93008e7c",
   "metadata": {},
   "source": [
    "# Conlusion <a id=Conclusion a>\n",
    "    \n",
    "After creating this intersection between the Echo Nest Taste Profile Subset and the LAkh MIDI Matched Subset, we are ready to move on to Exploratory Data Analysis. This is where we will begin lookin more deeply into the two datasets and their usability in our aim of finding the best recommendation system for a specific type of user.\n",
    "    \n",
    "As a note, in our initial exploration, as we cleaned the data, showed us the vast range of attributes that can be found within the Million Songs Dataset. This is very encouraging for future use, as there are many different potential additions to our dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
